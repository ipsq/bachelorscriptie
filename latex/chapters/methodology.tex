To show the positive impact big data has had on our ability to correctly model the term structure of interest rates, we will be comparing small data models with big data models. The models and predictive accuracy tests will be based on those presented in~\textcite{Swanson2017}. The small data models will include autoregressive, vector autoregressive, and dynamic Nelson-Siegel models. The big data models will include models utilizing diffusion indexes estimated from a macroeconomic dataset. 

The models will be (re-)estimated prior to construction of each forecast, using a rolling window of 120 months. The use of rolling windows is explained in~\cref{sec:dmtest}. Estimation of the models is done using least squares and, where necessary, (sparse) principal component analysis. Monthly yield forecasts for the horizons $h = 1-$, $3-$, and $12-$steps ahead are constructed for the bond maturities $\tau = 1-$, $2-$, $3-$, $5-$, and $10-$years. Performance of these models shall be assessed by mean square forecast error (MSFE) and models shall be compared for predictive accuracy using~\textcite[hereafter DM]{Diebold1994}. 

\subsection{Schwarz information criterion (SIC)}
\label{sec:sic}
The Schwarz information criterion, also commonly referred to as the Bayesian information criterion, published by~\textcite[hereafter SIC]{Schwarz1978} is a model selection criterium, closely related to the Akaike information criterion~\parencite{Akaike1974}. It is defined as follows
\begin{equation}
	SIC = k\ln{n} - 2\ln{\hat{L}}
\end{equation}
where $\hat{L}$ is the likelihood of the model, $n$ the number of observations and $k$ the number of model parameters estimated. The difference between SIC and AIC is the higher penalty given for the addition of extra parameters to compensate for the increase in likelihood.

\subsection{Autoregressive (AR) and Vector Autoregressive (VAR) Models}
\label{sec:arvar}
These AR($p$) and VAR($p$) models are formulated as follows:
\begin{equation}
	y_{t+1}(\tau) = c + \beta' W_t + \epsilon_{t+1},
\end{equation}
where $\tau$ denotes the maturity and $y_{t+1}(\tau)$ measures the 1-step ahead annual yield forecast of the bond. For the autoregressive model, $W_t$ contains $p$ lags of $y_{t+1}(\tau)$. For the vector autoregressive model, $W_t$ additionally contains yields of bonds of different maturities than $\tau$. In both models $\beta$ is a time-invariant coefficient vector and $c$ is a (vector of) constant(s). We will be including AR(1) and VAR(1) models as a baseline. Furthermore, we will be including AR and VAR specifications with up to 5 lags of $y_{t+1}(\tau)$ included. The number of lags shall be selected using the Schwarz information criterion (SIC), see~\cref{sec:sic}. These models shall be referenced by AR(SIC) and VAR(SIC). 

\subsection{Dynamic Nelson-Siegel (DNS) Models}
\label{sec:dns}
The Nelson-Siegel model, published by~\textcite{Nelson1987}, models the cross-sectional movement of the term structure using three underlying latent factors interpreted as \enquote{level}, \enquote{slope}, and \enquote{curvature}. These factors are commonly known as the \enquote{Nelson-Siegel factors}. The dynamic version of the Nelson-Siegel model was published by~\textcite[hereafter DNS]{Diebold2006}. The DNS model is formulated as follows:
\begin{equation}
	y_{t+1}(\tau) = \hat{\beta}_{1,t+1}^{f} + \hat{\beta}_{2,t+1}^{f} \left[\frac{1-\exp(-\lambda_t \tau)}{\lambda_t \tau}\right] + \hat{\beta}_{3,t+1}^{f} \left[\frac{1-\exp(-\lambda_t \tau)}{\lambda_t \tau} - \exp(-\lambda_t \tau)\right],
\end{equation}
where $\hat{\beta}_{1,t+1}^{f}$, $\hat{\beta}_{2,t+1}^{f}$, and $\hat{\beta}_{3,t+1}^{f}$ are estimated using an AR(1) model:
\begin{equation}
\label{eq:dnsar}
	\hat{\beta}_{i,t+1}^{f} = \hat{c}_i + \hat{\gamma}_{ii} \hat{\beta}_{i,t}^f, \quad \text{for}~i = 1,2,3,
\end{equation}
where $\hat{c}_i$, $\hat{\gamma}_{ii}$, and $\hat{\beta}_{i,t}^f$ are scalars. Alternatively, $\hat{\beta}_{1,t+1}^{f}$, $\hat{\beta}_{2,t+1}^{f}$, and $\hat{\beta}_{3,t+1}^{f}$ can also be estimated using a VAR(1) model:
\begin{equation}
\label{eq:dnsvar}
	\hat{\beta}_{t+1}^{f} = \hat{c} + \hat{\Gamma} \hat{\beta}_t^f,
\end{equation}
where $\hat{c}$ is a $3 \times 1$ vector, $\hat{\beta}_t^f = \left(\hat{\beta}_{1,t}^f, \hat{\beta}_{2,t}^f, \hat{\beta}_{3,t}^f\right)'$ a $3 \times 1$ vector, and $\hat{\Gamma} = \left(\hat{\gamma}_1, \hat{\gamma}_2, \hat{\gamma}_3 \right)$, with $\hat{\gamma}_j$ a $3 \times 1$ vector, for $j = 1,2,3$. The parameters $\hat{\beta}_{1,t}^f, \hat{\beta}_{2,t}^f, \hat{\beta}_{3,t}^f$ are obtained by regressing $\left\{1, \left[\frac{1-\exp(-\lambda_t \tau)}{\lambda_t \tau}\right], \left[\frac{1-\exp(-\lambda_t \tau)}{\lambda_t \tau} - \exp(-\lambda_t \tau)\right] \right\}$ on $\mathbf{y}_t^f(\tau)$. We will consider 3 variants of $\mathbf{y}_t^f(\tau)$ in this paper, namely:
\begin{align*}
	\mathbf{y}_t^{10}(\tau) &= \left[y_t(12)~y_t(24)~y_t(36)~y_t(48)~y_t(60)~y_t(72)~y_t(84)~y_t(96)~y_t(108)~y_t(120) \right]', \\
	\mathbf{y}_t^6(\tau) &= \left[y_t(12)~y_t(24)~y_t(36)~y_t(60)~y_t(84)~y_t(120) \right]', \\
	\mathbf{y}_t^4(\tau) &= \left[y_t(12)~y_t(36)~y_t(60)~y_t(120) \right]'.
\end{align*}
As discussed in \textcite{Diebold2006}, we will be setting the rate of decay, $\lambda_t$, to $0.0609$.

\subsection{DNS Models with Macroeconomic Variables}
\label{sec:dnsmv}
The DNS model, described in~\cref{sec:dns}, can be extended by including macroeconomic variables in the AR(1) model, given in~\cref{eq:dnsar}, as follows:
\begin{equation}
	\hat{\beta}_{i,t+1}^{f} = \hat{c}_i + \hat{\gamma}_{ii} \hat{\beta}_{i,t}^f + \hat{\alpha}_i' M_t, \quad \text{for}~i = 1,2,3,
\end{equation}
where $\hat{\alpha}_i$ is a $3 \times 1$ vector, and $M_t$ is a $3 \times 1$ vector containing the macroeconomic variables \enquote{manufacturing capacity utilization}, \enquote{the federal funds rate}, and \enquote{the annual personal consumption expenditures price deflator}. All other terms are conformably defined, see~\cref{sec:dns}. Analogous to the AR(1) model, the VAR(1) given in~\cref{eq:dnsvar}, can also be extended by including macroeconomic variables:
\begin{equation}
	\hat{\beta}_{t+1}^{f} = \hat{c} + \hat{\Gamma} \hat{\beta}_t^f + \hat{\mathrm{A}} M_t,
\end{equation}
where $\hat{\mathrm{A}} = \left(\hat{\alpha}_1, \hat{\alpha}_2, \hat{\alpha}_3 \right)$, with $\hat{\alpha}_j$ a $3 \times 1$ vector, for $j = 1,2,3$. All other terms are conformably defined, see~\cref{sec:dns}.

\subsection{Diffusion Index Models}
\label{sec:dif}
Diffusion Index Models, also commonly referred to as \enquote{factor augmented forecast models}, as published by~\textcite[hereafter DIF]{Stock2002a,Stock2002b}, is an extension to regular forecast models, mostly (vector-)autoregressive models, supplemented by a vector of latent factors. This model is formulated as follows:
\begin{equation}
	y_{t+1}(\tau) = c + \beta' W_t + \xi' F_t^b + \eta' F_t^s + \epsilon_{t+1},
\end{equation}
where $F_t^b$ contains either 1, 2, or 3 latent factors, estimated from the set of macroeconomic variables, using either PCA or SPCA (see~\cref{sec:spca}), $F_t^s$ contains either 1, 2, or 3 latent factors, estimated with PCA, from a set of 10 yields given by $\mathbf{y}_t^{10}(\tau)$, see~\cref{sec:dns}, and $\xi$ and $\eta$ are conformably sized (depending on the amount of factors included) vectors of coefficients. 

\subsection{DNS Models with Diffusion Indexes}
\label{sec:dnsdif}
The DNS model given in~\cref{sec:dns}, can also be extended by including diffusion indexes. The extended version of the AR model is formulated as follows:
\begin{equation}
	\hat{\beta}_{i,t+1}^{f} = \hat{c}_i + \hat{\gamma}_{ii} \hat{\beta}_{i,t}^f + \hat{\xi}' F_t^b, \quad \text{for}~i = 1,2,3,
\end{equation}
where $F_t^b$ is defined as in~\cref{sec:dif} and $\hat{\xi}$ is a conformably sized (depending on the amount of factors included) vector of coefficients. All other terms are conformably defined, see~\cref{sec:dns}. Analogous to the AR(1) model, the VAR(1) given in~\cref{eq:dnsvar}, can also be extended by including diffusion indexes:
\begin{equation}
	\hat{\beta}_{t+1}^{f} = \hat{c} + \hat{\Gamma} \hat{\beta}_t^f + \hat{\Xi} F_t^b,
\end{equation}
where $\hat{\Xi}$ is a conformably sized (depending on the amount of factors included) matrix of coefficients. All other terms are conformably defined, see~\cref{sec:dns}.

\subsection{Sparse Principal Component Analysis (SPCA)}
\label{sec:spca}
Diffusion indexes estimated with Principal Component Analysis create linear combinations of the underlying predictor variables with all non-zero factor loadings. This negatively affects the parsimony of forecasting models. Techniques have been published to estimate principal components with sparse factor loadings, see~\textcite{Zou2006}. One of these techniques is called the \enquote{elastic net}, formulated as follows:
\begin{equation}
	\theta_{elastic\ net} = (1 + \lambda_2) \arg \underset{\theta}{\min} \left\{{\left\| y - \sum_{i=0}^{N} X_i \theta_i \right\|}^2 + \lambda_1 \sum_{j=1}^N \left|\theta_j\right| + \lambda_2 \sum_{j=1}^N \theta_j^2 \right\}
\end{equation}
where $y$ is a $T \times 1$ target vector, $X_i = \left(X_{1,i}, \dots, X_{T,i}\right)'$ is a $T \times 1$ predictor vector, and $\lambda_1$ and $\lambda_2$ are tuning parameters.

\subsection{Diebold-Mariano (DM) Test}
\label{sec:dmtest}
The Diebold-Mariano Test, published by~\textcite[hereafter DM]{Diebold1994}, is a predictive accuracy test between two models. The hypotheses are defined as follows:
\begin{align*}
	H_0 : E\left[L(u_{0,t+h}) - L(u_{1,t+h})\right] = 0, \\
	H_A : E\left[L(u_{0,t+h}) - L(u_{1,t+h})\right] \neq 0,
\end{align*}
where $L(\cdot)$ is a loss function, and $u_{0,t+h}$ and $u_{1,t+h}$ are $h$-step ahead forecast errors. In practice, we only observe estimates of these out-of-sample $h$-step ahead forecasts, i.e. $\hat{u}_{0,t+h}$ and $\hat{u}_{1,t+h}$. The standard version of the DM predictive accuracy test is formulated as follows:
\begin{equation}
	DM_p = \frac{\bar{d_t}}{\hat{\sigma}_{\bar{d}_t}} \overset{d}{\rightarrow} N(0,1),
\end{equation}
where
\begin{equation}
	\bar{d}_t = \frac{1}{P} \sum_{t=R+1}^{T} d_t,\ d_t = L(\hat{u}_{0,t+h}) - L(\hat{u}_{1,t+h}),\ \text{and}\ \hat{\sigma}_{\bar{d}_t} = \frac{\hat{\sigma}_{d_t}}{\sqrt{P}}.
\end{equation}
In the formulation above, $P$ is defined as the number of forecasts, $R$ is defined as the number of observations in the training sample, and $T = P + R$. 
